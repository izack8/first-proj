{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To build an ARIMA model (resources):\n",
    "- https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n",
    "- https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/\n",
    "\n",
    "We first need the time-series to be **stationary**. Visually, a stationary time series graph would appear as a relatively flat line with random fluctuations around a constant mean. The data points would show no apparent trend, seasonality, or systematic patterns. The spread or dispersion of the data points around the mean would be consistent throughout the series.\n",
    "\n",
    "The parameters of the ARIMA model are defined as follows:\n",
    "\n",
    "**`p`** (AR): The number of lag observations included in the model, also called the lag order.\n",
    "\n",
    "**`d`**: The number of times that the raw observations are differenced, also called the degree of differencing. (differencing is needed for the graph to be stationary)\n",
    "\n",
    "**`q`** (MA): The size of the moving average window, also called the order of moving average."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `d` part\n",
    "\n",
    "Because, term ‘Auto Regressive’ in ARIMA means it is a linear regression model that uses its own lags as predictors. (self-predict-self)\n",
    "\n",
    "Linear regression models, as you know, work best when the predictors are **not** correlated and are independent of each other.\n",
    "\n",
    "To do that, we need to make our data **stationary**. To determine that the data has became stationary, ACF is implemented after differencing.\n",
    "\n",
    "1. An ACF plot that shows a rapid decrease in correlation value in the first few time-lags (usually less than 10), indicates a good stationarity. \n",
    "2. \n",
    "\n",
    "A stationary time series, with stable mean, variance, and autocorrelation, implies that the patterns observed in the past **are likely to persist** in the future. By analyzing the historical data, such as trends, seasonal patterns, and cyclic behavior, one can make informed predictions about future values. The stationary nature of the plot allows the model to capture these patterns accurately.\n",
    "\n",
    "Though differencing may seem like taking away previous data crucial for prediction, it is actually the underlying stastistical values (like mean, variance, correlation) that the model is capturing, and using for its prediction.\n",
    "\n",
    "This helps the selection process of `p` and `q`. \n",
    "\n",
    "The number of differencing made is `d`. The right order of differencing is the minimum differencing required to get a near-stationary series which roams around a defined mean and the ACF plot reaches to zero fairly quick."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `p` part\n",
    "\n",
    "By implementing `PACF` or `Partial Autocorrelation Function`, "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
